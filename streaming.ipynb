{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/18 11:54:51 WARN Utils: Your hostname, Niharikas-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.0.77 instead (on interface en0)\n",
      "24/01/18 11:54:51 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/01/18 11:54:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = (SparkSession.builder.appName(\"Activity Tracker\").getOrCreate())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:===========================================>              (9 + 3) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Arrival_Time: long (nullable = true)\n",
      " |-- Creation_Time: long (nullable = true)\n",
      " |-- Device: string (nullable = true)\n",
      " |-- Index: long (nullable = true)\n",
      " |-- Model: string (nullable = true)\n",
      " |-- User: string (nullable = true)\n",
      " |-- gt: string (nullable = true)\n",
      " |-- x: double (nullable = true)\n",
      " |-- y: double (nullable = true)\n",
      " |-- z: double (nullable = true)\n",
      "\n",
      "+-------------+-------------------+--------+-----+------+----+-----+-------------+------------+------------+\n",
      "| Arrival_Time|      Creation_Time|  Device|Index| Model|User|   gt|            x|           y|           z|\n",
      "+-------------+-------------------+--------+-----+------+----+-----+-------------+------------+------------+\n",
      "|1424686735090|1424686733090638193|nexus4_1|   18|nexus4|   g|stand|  3.356934E-4|-5.645752E-4|-0.018814087|\n",
      "|1424686735292|1424688581345918092|nexus4_2|   66|nexus4|   g|stand| -0.005722046| 0.029083252| 0.005569458|\n",
      "|1424686735500|1424686733498505625|nexus4_1|   99|nexus4|   g|stand|    0.0078125|-0.017654419| 0.010025024|\n",
      "|1424686735691|1424688581745026978|nexus4_2|  145|nexus4|   g|stand| -3.814697E-4|   0.0184021|-0.013656616|\n",
      "|1424686735890|1424688581945252808|nexus4_2|  185|nexus4|   g|stand| -3.814697E-4|-0.031799316| -0.00831604|\n",
      "|1424686736094|1424686734097840342|nexus4_1|  218|nexus4|   g|stand| -7.324219E-4|-0.013381958|  0.01109314|\n",
      "|1424686736294|1424688582347932252|nexus4_2|  265|nexus4|   g|stand| -0.005722046| 0.015197754| 0.022659302|\n",
      "|1424686736495|1424688582549592408|nexus4_2|  305|nexus4|   g|stand| -3.814697E-4|0.0087890625|0.0034332275|\n",
      "|1424686736697|1424688582750703248|nexus4_2|  345|nexus4|   g|stand|  0.002822876|-0.008300781|-0.015792847|\n",
      "|1424686736898|1424688582952241334|nexus4_2|  385|nexus4|   g|stand|  6.866455E-4|-0.008300781| 0.004501343|\n",
      "|1424686737100|1424686735109928643|nexus4_1|  418|nexus4|   g|stand|  0.003540039|-0.010177612|-0.026290894|\n",
      "|1424686737300|1424688583355164918|nexus4_2|  465|nexus4|   g|stand|  0.002822876|0.0045166016|-0.014724731|\n",
      "|1424686737505|1424686735512935017|nexus4_1|  498|nexus4|   g|stand| 0.0024719238|-0.010177612|-0.017745972|\n",
      "|1424686737707|1424686735709254597|nexus4_1|  537|nexus4|   g|stand|-0.0028686523|-0.003768921| 0.020706177|\n",
      "|1424686737908|1424686735915675495|nexus4_1|  578|nexus4|   g|stand|-0.0028686523| 0.026138306| 0.007888794|\n",
      "|1424686738109|1424688584160372793|nexus4_2|  625|nexus4|   g|stand| -3.814697E-4| 2.441406E-4| 0.033340454|\n",
      "|1424686738326|1424688584381747305|nexus4_2|  661|nexus4|   g|stand| 0.0017547607| 0.019470215|-0.011520386|\n",
      "|1424686738529|1424686736534938191|nexus4_1|  701|nexus4|   g|stand| 0.0024719238|-0.033676147|0.0068206787|\n",
      "|1424686738744|1424688584799723655|nexus4_2|  744|nexus4|   g|stand| -3.814697E-4|-0.002960205|-0.027542114|\n",
      "|1424686738935|1424686736943477009|nexus4_1|  782|nexus4|   g|stand| -0.009277344|-0.009109497|  -0.0690155|\n",
      "+-------------+-------------------+--------+-----+------+----+-----+-------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# in Python\n",
    "static = spark.read.json(\"Data/Spark/data/activity-data/\")\n",
    "static.printSchema()\n",
    "static.show()\n",
    "dataSchema = static.schema\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming = spark.readStream.schema(dataSchema).option(\"maxFilesPerTrigger\", 1)\\\n",
    "  .json(\"Data/Spark/data/activity-data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activityCounts = streaming.groupBy(\"gt\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/18 11:54:59 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /private/var/folders/tw/0sj1sbk54zjft6x3s_xgp0r00000gp/T/temporary-0572b2d4-8fc8-4e9d-8030-08e7294fa479. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "24/01/18 11:54:59 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    }
   ],
   "source": [
    "activityQuery = activityCounts.writeStream.queryName(\"activity_counts\")\\\n",
    "  .format(\"memory\").outputMode(\"complete\")\\\n",
    "  .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activityQuery.awaitTermination()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pyspark.sql.streaming.query.StreamingQuery at 0x107257b50>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.streams.active\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count using SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| gt|count|\n",
      "+---+-----+\n",
      "+---+-----+\n",
      "\n",
      "+----------+-----+\n",
      "|        gt|count|\n",
      "+----------+-----+\n",
      "|       sit|12309|\n",
      "|     stand|11384|\n",
      "|stairsdown| 9365|\n",
      "|      walk|13256|\n",
      "|  stairsup|10452|\n",
      "|      null|10449|\n",
      "|      bike|10796|\n",
      "+----------+-----+\n",
      "\n",
      "+----------+-----+\n",
      "|        gt|count|\n",
      "+----------+-----+\n",
      "|       sit|73855|\n",
      "|     stand|68309|\n",
      "|stairsdown|56192|\n",
      "|      walk|79536|\n",
      "|  stairsup|62710|\n",
      "|      null|62688|\n",
      "|      bike|64781|\n",
      "+----------+-----+\n",
      "\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|123085|\n",
      "|     stand|113849|\n",
      "|stairsdown| 93648|\n",
      "|      walk|132560|\n",
      "|  stairsup|104521|\n",
      "|      null|104482|\n",
      "|      bike|107974|\n",
      "+----------+------+\n",
      "\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|184620|\n",
      "|     stand|170778|\n",
      "|stairsdown|140456|\n",
      "|      walk|198839|\n",
      "|  stairsup|156800|\n",
      "|      null|156721|\n",
      "|      bike|161965|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "for x in range(5):\n",
    "    spark.sql(\"SELECT * FROM activity_counts\").show()\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/18 11:55:04 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /private/var/folders/tw/0sj1sbk54zjft6x3s_xgp0r00000gp/T/temporary-287a9c08-a159-4918-8d00-cab66f73c0be. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "24/01/18 11:55:04 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "simpleTransform = streaming.withColumn(\"stairs\", expr(\"gt like '%stairs%'\"))\\\n",
    "  .where(\"stairs\")\\\n",
    "  .where(\"gt is not null\")\\\n",
    "  .select(\"gt\", \"model\", \"arrival_time\", \"creation_time\")\\\n",
    "  .writeStream\\\n",
    "  .queryName(\"simple_transform\")\\\n",
    "  .format(\"memory\")\\\n",
    "  .outputMode(\"append\")\\\n",
    "  .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/18 11:55:05 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /private/var/folders/tw/0sj1sbk54zjft6x3s_xgp0r00000gp/T/temporary-6108089b-7963-446a-bb46-e924a019f532. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "24/01/18 11:55:05 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    }
   ],
   "source": [
    "deviceModelStats = streaming.cube(\"gt\", \"model\").avg()\\\n",
    "  .drop(\"avg(Arrival_time)\")\\\n",
    "  .drop(\"avg(Creation_Time)\")\\\n",
    "  .drop(\"avg(Index)\")\\\n",
    "  .writeStream.queryName(\"device_counts\").format(\"memory\")\\\n",
    "  .outputMode(\"complete\")\\\n",
    "  .start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### device count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "|        gt| model|              avg(x)|              avg(y)|              avg(z)|\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "|       sit|  NULL| -5.4943324403959E-4|2.791446281700071E-4|-2.33994461689892...|\n",
      "|      walk|nexus4|-0.00390116006094...|0.001052508689953...|-6.95435553042998...|\n",
      "|      walk|  NULL|-0.00390116006094...|0.001052508689953...|-6.95435553042998...|\n",
      "|  stairsup|  NULL|-0.02479965287771643|-0.00800392344379...|-0.10034088415060415|\n",
      "|     stand|  NULL|-3.11082189691727...|3.218461665975321...|2.141300040636463...|\n",
      "|      bike|  NULL|0.022688759550866838|-0.00877912156368...|-0.08251001663412372|\n",
      "|  stairsup|nexus4|-0.02479965287771643|-0.00800392344379...|-0.10034088415060415|\n",
      "|      NULL|nexus4|4.796918779024287E-4|-0.00601540958963...|-0.01013356489164...|\n",
      "|      NULL|  NULL|4.796918779024287E-4|-0.00601540958963...|-0.01013356489164...|\n",
      "|stairsdown|  NULL|0.021613908669165335|-0.03249018824752615| 0.12035922691504052|\n",
      "|      null|  NULL|-0.00847688860109...|-7.30455258739179...|0.003090601491419903|\n",
      "|       sit|nexus4| -5.4943324403959E-4|2.791446281700071E-4|-2.33994461689892...|\n",
      "|stairsdown|nexus4|0.021613908669165335|-0.03249018824752615| 0.12035922691504052|\n",
      "|     stand|nexus4|-3.11082189691727...|3.218461665975321...|2.141300040636463...|\n",
      "|      null|nexus4|-0.00847688860109...|-7.30455258739179...|0.003090601491419903|\n",
      "|      bike|nexus4|0.022688759550866838|-0.00877912156368...|-0.08251001663412372|\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM device_counts\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
